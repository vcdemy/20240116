{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vcdemy/20240116/blob/main/20240123%E7%AD%86%E8%A8%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7816912d-165e-493c-b352-304427b7fe6b",
      "metadata": {
        "id": "7816912d-165e-493c-b352-304427b7fe6b"
      },
      "source": [
        "# 20240123 筆記"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0b727b-722d-4ae8-ad43-54f33bf2b17b",
      "metadata": {
        "tags": [],
        "id": "ac0b727b-722d-4ae8-ad43-54f33bf2b17b",
        "outputId": "53fb059b-51c2-498a-97f3-acca0863ce5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\victor\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
        "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8477ede-9368-4258-ba28-b66eb69ff497",
      "metadata": {
        "tags": [],
        "id": "f8477ede-9368-4258-ba28-b66eb69ff497",
        "outputId": "13ed7778-6eec-48f0-8e4f-d50887e33aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\victor\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\victor\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "1/1 [==============================] - 1s 976ms/step\n",
            "Class: Glass\n",
            "Confidence Score: 0.7306934\n"
          ]
        }
      ],
      "source": [
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"keras_model.h5\", compile=False)\n",
        "\n",
        "# Load the labels\n",
        "class_names = open(\"labels.txt\", \"r\").readlines()\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open(\"data/glass/glass110.jpg\").convert(\"RGB\")\n",
        "\n",
        "# resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
        "\n",
        "# turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
        "\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# Predicts the model\n",
        "prediction = model.predict(data)\n",
        "index = np.argmax(prediction)\n",
        "class_name = class_names[index]\n",
        "confidence_score = prediction[0][index]\n",
        "\n",
        "# Print prediction and confidence score\n",
        "print(\"Class:\", class_name[2:], end=\"\")\n",
        "print(\"Confidence Score:\", confidence_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0916ea7-8965-498c-9cd7-bfaa179a1cd2",
      "metadata": {
        "tags": [],
        "id": "e0916ea7-8965-498c-9cd7-bfaa179a1cd2"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b310fe-fd18-4a29-b993-900da21c83a8",
      "metadata": {
        "tags": [],
        "id": "a5b310fe-fd18-4a29-b993-900da21c83a8"
      },
      "outputs": [],
      "source": [
        "def predict(image):\n",
        "    # Disable scientific notation for clarity\n",
        "    np.set_printoptions(suppress=True)\n",
        "\n",
        "    # Load the model\n",
        "    model = load_model(\"keras_model.h5\", compile=False)\n",
        "\n",
        "    # Load the labels\n",
        "    class_names = open(\"labels.txt\", \"r\").readlines()\n",
        "\n",
        "    # Create the array of the right shape to feed into the keras model\n",
        "    # The 'length' or number of images you can put into the array is\n",
        "    # determined by the first position in the shape tuple, in this case 1\n",
        "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "    # Replace this with the path to your image\n",
        "    # image = Image.open(\"data/glass/glass110.jpg\").convert(\"RGB\")\n",
        "\n",
        "    # resizing the image to be at least 224x224 and then cropping from the center\n",
        "    size = (224, 224)\n",
        "    image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
        "\n",
        "    # turn the image into a numpy array\n",
        "    image_array = np.asarray(image)\n",
        "\n",
        "    # Normalize the image\n",
        "    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
        "\n",
        "    # Load the image into the array\n",
        "    data[0] = normalized_image_array\n",
        "\n",
        "    # Predicts the model\n",
        "    prediction = model.predict(data)\n",
        "    index = np.argmax(prediction)\n",
        "    class_name = class_names[index]\n",
        "    confidence_score = prediction[0][index]\n",
        "\n",
        "    # Print prediction and confidence score\n",
        "    print(\"Class:\", class_name[2:], end=\"\")\n",
        "    print(\"Confidence Score:\", confidence_score)\n",
        "    return class_name[2:], confidence_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891df208-7e0b-45e6-b83e-ffd596eb74d1",
      "metadata": {
        "tags": [],
        "id": "891df208-7e0b-45e6-b83e-ffd596eb74d1",
        "outputId": "5f6cac08-dd19-4d5a-b51b-750e4c832acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Class: cardboard\n",
            "Confidence Score: 0.99991465\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Class: Plastic\n",
            "Confidence Score: 0.9992405\n"
          ]
        }
      ],
      "source": [
        "gr.Interface(predict, gr.Image(type='pil'), ['text', 'text']).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8545e9c9-05b7-4f6c-bcf8-8a6ee6f45653",
      "metadata": {
        "id": "8545e9c9-05b7-4f6c-bcf8-8a6ee6f45653"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}